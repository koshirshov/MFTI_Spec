{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы применим аппарат тематического моделирования к коллекции текстовых записей видеолекций, скачанных с сайта Постнаука. Мы будем визуализировать модель и создавать прототип тематического навигатора по коллекции. В коллекции 1728 документов, размер словаря - 38467 слов. Слова лемматизированы, то есть приведены к начальной форме, с помощью программы mystem, коллекция сохранена в формате vowpal wabbit. В каждой строке до первой черты записана информация о документе (ссылка на страницу с лекцией), после первой черты следует описание документа. Используются две модальности - текстовая (\"text\") и модальность авторов (\"author\"); у каждого документа один автор.\n",
    "\n",
    "Для выполнения задания понадобится библиотека BigARTM. В демонстрации показан пример использования библиотеки версии 0.7.4, на сайте предлагается скачивать версию 0.8.0. В новой версии изменены принципы работы со словарями: они вынесены в отдельный класс (пример в Release Notes). Строить модель и извлекать ее параметры нужно так же, как показано в демонстрации. Вы можете использовать предыдущий релиз или новый релиз на ваше усмотрение.\n",
    "\n",
    "Спецификации всех функций вы можете смотреть на странице Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import artm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "#параллелльного запуска одной функции с разными параметрами в параллельных потоках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#принтит все, а не последнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1\n",
    "2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте объект класса artm.BatchVectorizer, который будет ссылаться на директорию с пакетами данных (батчами). Чтобы библиотека могла преобразовать текстовый файл в батчи, создайте пустую директорию и укажите ее название в параметре target_folder. Размер батча для небольших коллекций (как наша) не важен, вы можете указать любой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_vectorizer = artm.BatchVectorizer(data_path='lectures.txt', data_format='vowpal_wabbit',target_folder=\"lectures_batches\", batch_size=250)\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path=\"lectures_batches\", data_format='batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Инициализация модели\n",
    "\n",
    "Создайте объект класса artm.Model с 30 темами, именами тем, указанными ниже и единичными весами обеих модальностей. Количество тем выбрано не очень большим, чтобы вам было удобнее работать с темами. На этой коллекции можно строить и большее число тем, тогда они будут более узко специализированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] Не найден указанный модуль\nFailed to load artm shared library from `['artm.dll', 'C:\\\\BigARTM\\\\Python\\\\artm\\\\wrapper\\\\..\\\\artm.dll']`. Try to add the location of `artm.dll` file into your PATH system variable, or to set ARTM_SHARED_LIBRARY - the specific system variable which may point to `artm.dll` file, including the full path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b054b921d0d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtopic_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sbj\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bcg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m model_artm = artm.ARTM(num_topics=T, topic_names=topic_names, class_ids={'text':1, 'author':1}, \n\u001b[1;32m----> 5\u001b[1;33m                        num_processors=2, reuse_theta=True, cache_theta=True, seed=-1)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# число после названия модальностей - это их веса\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\BigARTM\\Python\\artm\\artm_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_topics, topic_names, num_processors, class_ids, scores, regularizers, num_document_passes, reuse_theta, dictionary, cache_theta, theta_columns_naming, seed, show_progress_bars, theta_name)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_theta_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLibArtm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mmaster_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMasterModelConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtheta_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\BigARTM\\Python\\artm\\wrapper\\api.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lib_name, logging_config)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLibArtm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_cdll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# adding specified functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\BigARTM\\Python\\artm\\wrapper\\api.py\u001b[0m in \u001b[0;36m_load_cdll\u001b[1;34m(self, lib_name)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;34m'which may point to `{default_lib_name}` file, including the full path.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             ).format(**locals())\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcdll\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] Не найден указанный модуль\nFailed to load artm shared library from `['artm.dll', 'C:\\\\BigARTM\\\\Python\\\\artm\\\\wrapper\\\\..\\\\artm.dll']`. Try to add the location of `artm.dll` file into your PATH system variable, or to set ARTM_SHARED_LIBRARY - the specific system variable which may point to `artm.dll` file, including the full path."
     ]
    }
   ],
   "source": [
    "#Создаем объект модели:\n",
    "T = 30   # количество тем\n",
    "topic_names=[\"sbj\"+str(i) for i in range(T-1)]+[\"bcg\"]\n",
    "model_artm = artm.ARTM(num_topics=T, topic_names=topic_names, class_ids={'text':1, 'author':1}, \n",
    "                       num_processors=2, reuse_theta=True, cache_theta=True, seed=-1)\n",
    "# число после названия модальностей - это их веса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Мы будем строить 29 предметных тем и одну фоновую.\n",
    "\n",
    "Соберите словарь с помощью метода gather_dictionary и инициализируйте модель, указав random_seed=1. Обязательно укажите свое название словаря, оно понадобится при добавлении регуляризаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "np.random.seed(1)\n",
    "dictionary = artm.Dictionary('dict')\n",
    "dictionary.gather(batch_vectorizer.data_path)\n",
    "#Инициализируем модель с помощью созданного ранее словаря\n",
    "model_artm.initialize(dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Добавление score\n",
    "\n",
    "Создайте два измерителя качества artm.TopTokensScore - по одному для каждой модальности; количество токенов 15. Названия для score придумайте самостоятельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.scores.add(artm.PerplexityScore(name='PerplexityScore',\n",
    "                                          # use_unigram_document_model=False,\n",
    "                                           dictionary='dictionary'))\n",
    "model_artm.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore', class_id=\"text\"))\n",
    "model_artm.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model_artm.scores.add(artm.TopTokensScore(name=\"top_tokens_score_mod1\", num_tokens=15, class_id=\"text\"))\n",
    "model_artm.scores.add(artm.TopTokensScore(name=\"top_tokens_score_mod2\", num_tokens=15, class_id=\"author\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели\n",
    "Мы будем строить модель в два этапа: сначала добавим сглаживающий регуляризатор фоновой темы и настроим параметры модели, затем - добавим разреживающий регуляризатор предметрых тем и выполним еще несколько итераций. Так мы сможем получить наиболее чистые от фоновых слов предметные темы. Сглаживающий и разреживающий регуляризаторы задаются одним и тем же классом artm.SmoothSparsePhiRegularizer: если коэффициент tau положительный, то регуляризатор будет сглаживающий, если отрицательный - разреживающий.\n",
    "\n",
    "Если вы хотите подробнее разобраться, как выполняется регуляризация тематической модели в BigARTM, вы можете прочитать статью, раздел 4.(https://s3-eu-west-1.amazonaws.com/artm/voron-potap14artm-rus.pdf)\n",
    "\n",
    "Добавьте сглаживающий регуляризатор с коэффициентом tau = 1e5, указав название своего словаря в dictionary, модальность текста в class_ids и тему \"bcg\" в topic_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(tau=1e5\n",
    "                    , class_ids='text', dictionary=dictionary, topic_names='bcg', name = 'Сглаживающий'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Выполните 30 итераций по коллекции (num_collection_passes), количество внутренних итераций установите равным 1. Используйте метод fit_offline модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.num_document_passes = 1\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Добавьте разреживающий регуляризатор с коэффициентом tau=-1e5, указав название своего словаря, модальность текста в class_ids и все темы \"sbjX\" в topic_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_names_cleared  = topic_names.remove('bcg')\n",
    "model_artm.regularizers.add(artm.SmoothSparsePhiRegularizer(tau=-1e5, class_ids='text', dictionary=dictionary,\n",
    "                    topic_names=topic_names_cleared, name = 'Разреживающий'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Выполните еще 15 проходов по коллекции.\n",
    "model_artm.fit_offline(batch_vectorizer=batch_vectorizer, num_collection_passes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация тем\n",
    "Используя созданные score, выведите топы слов и топы авторов в темах. Удобнее всего выводить топ слов каждой темы с новой строки, указывая название темы в начале строки, и аналогично с авторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.score_tracker['top_tokens_score_mod1'].last_tokens['bcg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.score_tracker['top_tokens_score_mod2'].last_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дайте названия 29 предметным темам. Если вы не знаете, как назвать тему, назовите ее первым встретившимся в ней существительным, хотя при таком подходе навигатор будет менее информативным. Из названий тем составьте список из 29 строк и запишите го в переменную sbj_topic_labels. В переменной topic_labels будут храниться названия всех тем, включая фоновую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = model_artm.score_tracker['top_tokens_score_mod1'].last_tokens\n",
    "sbj_topic_labels = []   # запишите названия тем в список\n",
    "for topic_name in model_artm.topic_names[:29]:\n",
    "    sbj_topic_labels.append(tokens[topic_name][0])\n",
    "\n",
    "topic_labels = sbj_topic_labels + [u\"Фоновая тема\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Анализ тем\n",
    "Далее мы будем работать с распределениями тем в документах (матрица $\\Theta$) и авторов в темах (одна из двух матриц $\\Phi$, соответствующая модальности авторов). Создайте переменные, содержащие две этих матрицы, с помощью методов get_phi и get_theta модели. Назовите переменные theta и phi_a. Выведите формы обеих матриц, чтобы понять, по каким осям стоят темы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artm.theta_columns_naming = \"title\" # включает именование столбцов Theta их названиями-ссылками, а не внутренними id \n",
    "# Ваш код\n",
    "theta = model_artm.get_theta()\n",
    "print('Theta shape: %s' % str(theta.shape))\n",
    "phi_a = model_artm.get_phi(class_ids='author')\n",
    "print('Phi_a shape: %s' % str(phi_a.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем фрагмент матрицы $\\Theta$ - первые 100 документов (это наиболее простой способ визуально оценить, как темы распределяются в документах). С помощью метода seaborn.heatmap выведите фрагмент theta как изображение. Рекомендация: создайте фигуру pyplot размера (20, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta.iloc[:,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Theta matrix for the first 100 documents')\n",
    "sns.heatmap(theta.iloc[:,:100], cmap='YlGnBu', xticklabels=False)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы должны увидеть, что фоновая тема имеет большую вероятность в почти каждом документе, и это логично. Кроме того, есть еще одна тема, которая чаще других встречается в документах. Судя по всему, это тема содержит много слов по науку в целом, а каждый документ (видео) в нашей коллекции связан с наукой. Можно (необязательно) дать этой теме название \"Наука\".\n",
    "\n",
    "Помимо этих двух тем, фоновой и общенаучной, каждый документ характеризуется малым числом других тем.\n",
    "\n",
    "Оценим $p(t)$ - долю каждой темы во всей коллекции. По формуле полной вероятности вычислять эти величины нужно как $p(t) = \\sum_d p(t|d) p(d)$. Согласно вероятностной модели, $p(d)$ пропорционально длине документа d. Поступим проще: будем полагать, что все документы равновероятны. Тогда оценить $p(t)$ можно, просуммировав $p(t|d)$ по всем документам, а затем разделив полученный вектор на его сумму.\n",
    "\n",
    "Создайте переменную-датафрейм с T строками, индексированными названиями тем, и 1 столбцом, содержащим оценки $p(t)$. Выведите датафрейм на печать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_theme_data = [np.sum(theta.iloc[i]) for i in range(theta.shape[0])]\n",
    "prob_theme_data_normed = prob_theme_data / np.sum(prob_theme_data)\n",
    "prob_theme = pd.DataFrame(data=prob_theme_data_normed, index=topic_labels, columns=['prob'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_themes = pd.DataFrame(theta.sum(axis = 1)/theta.sum(axis = 1).sum())\n",
    "prob_themes.columns = ['probability']\n",
    "prob_themes.index = topic_labels\n",
    "prob_themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируйте матрицу $\\Phi$ модальности авторов в виде изображения. Рекомендация: установите yticklabels=False в heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Theta matrix for the first 100 documents')\n",
    "sns.heatmap(phi_a.iloc[:100], cmap='YlGnBu', yticklabels=False)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Каждой теме соответствует не очень большое число авторов - матрица достаточно разреженная. Кроме того, некоторые темы имеют доминирующего автора $a$, имеющего большую вероятность $p(a|t)$ - этот автор записал больше всего лекций по теме.\n",
    "\n",
    "Будем считать, что автор $a$ значим в теме, если $p(a|t) &gt; 0.01$. Для каждого автора посчитайте, в скольких темах он значим. Найдите авторов-рекордсменов, которые значимы (а значит, читали лекции) в >= 3 темах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(phi_a.shape[0]):\n",
    "    num_valuble_topics = 0\n",
    "    for val in phi_a.iloc[i]:\n",
    "        if val > 0.01:\n",
    "            num_valuble_topics += 1\n",
    "    if num_valuble_topics >= 3:\n",
    "        print(i, phi_a.index[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение тематической карты авторов\n",
    "По сути, в матрице $\\Phi$, соответствующей модальности авторов, записаны тематические кластеры авторов. Для любого автора мы можем составить его тематический круг - авторов, разбирающихся в той же теме, что и данный. Интересующиеся слушатели могут попробовать выполнить эту процедуру для ученых, читающих лекции на Постнауке, которых они знают (например, на Постнауке есть лекции с К. В. Воронцовым - лектором текущего модуля :)\n",
    "\n",
    "Составим карту близости авторов по тематике их исследований. Для этого применим метод понижения размерности MDS к тематическим профилям авторов.\n",
    "\n",
    "Чтобы получить тематический профиль автора, распределение $p(t|a)$, нужно воспользоваться формулой Байеса: $p(t|a) = \\frac {p(a|t) p(t)} {\\sum_t' p(a|t') p(t')}$. Все необходимые для этого величины у вас есть и записаны в переменных phi и pt.\n",
    "\n",
    "Передайте матрицу тематических профилей авторов, записанных по строкам, в метод MDS с n_components=2. Используйте косинусную метрику (она хорошо подходит для поиска расстояний между векторами, имеющими фиксированную сумму компонент)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics import pairwise_distances\n",
    "phi_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "themes_autors = np.empty(shape = phi_a.shape)\n",
    "for i in range(0, themes_autors.shape[0]):\n",
    "    for j in range(themes_autors.shape[1]):\n",
    "        themes_autors[i,j] = phi_a.iloc[i,j]*prob_theme.iloc[j] / (np.sum(phi_a.iloc[i,:] * prob_theme.prob.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prob_theme.prob.values.shape\n",
    "phi_a.iloc[i,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "similarities = pairwise_distances(themes_autors, metric='cosine')\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "pos = mds.fit_transform(similarities)\n",
    "\n",
    "# Ваш код\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(pos[:,0], pos[:,1])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Должно получиться, что некоторые грппы авторов формируют сгустки, которые можно считать тематическими группами авторов.\n",
    "\n",
    "Раскрасим точки следующим образом: для каждого автора выберем наиболее вероятную для него тему ($\\max_t p(t|a)$), и каждой теме сопоставим цвет. Кроме того, добавим на карту имена и фамилии авторов, это можно сделать в цикле по всем точкам с помощью функции plt.annotate, указывая метку точки первым аргументом и ее координаты в аргументе xy. Рекомендуется сделать размер изображения большим, тогда маркеры точек тоже придется увеличить (s=100 в plt.scatter). Изобразите карту авторов и сохраните в pdf-файл с помощью функции plt.savefig.\n",
    "\n",
    "Метки авторов будут пересекаться. Будет очень хорошо, если вы найдете способ, как этого можно избежать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len([np.argmax(author) for author in themes_autors])\n",
    "pos[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "colors = cm.rainbow(np.linspace(0, 1, T)) # цвета для тем\n",
    "# Ваш код\n",
    "max_theme_prob_for_colors = [np.argmax(author) for author in themes_autors]\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.axis('off')\n",
    "plt.scatter(pos[:,0], pos[:,1], s=100, c=colors[max_theme_prob_for_colors])\n",
    "for i, author in enumerate(phi_a.index):\n",
    "        plt.annotate(author, pos[i])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание простого тематического навигатора по Постнауке\n",
    "Наш тематический навигатор будет для каждой темы показывать ее список слов, а также список релевантных теме документов.\n",
    "\n",
    "Нам понадобятся распределения $p(d|t)$. По формуле Байеса $p(d|t) = \\frac{p(t|d)p(d)}{\\sum_{d'}p(t|d')p(d')}$, но поскольку мы считаем документы равновероятными, достаточно разделить каждую строку $\\Theta$ на ее сумму, чтобы оценить распределение.\n",
    "\n",
    "Отсортируйте матрицу $p(d|t)$ по убыванию $p(d|t)$ в каждой теме (то есть построчно). Нам понадобятся индексы наиболее вероятных документов в каждой теме, поэтому используйте функцию argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "prob_doc_theme = theta.values / np.array([np.sum(theme) for theme in theta.values])[:, np.newaxis]\n",
    "prob_doc_theme_sorted_indices = prob_doc_theme.argsort(axis=1)[:,::-1]\n",
    "prob_doc_theme_sorted_indices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В цикле для каждой темы выведите ее заголовок, в следующей строке - топ-10 слов темы, затем в виде списка ссылки на 10 наиболее релевантных (по $p(d|t)$) теме документов. Используйте html-разметку. Творчество приветствуется :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(u\"<h1>Заголовок</h1>\"))   # также <h2>, <h3>\n",
    "display(HTML(u\"<ul><li>Пункт 1</li><li>Пункт 2</li></ul>\"))\n",
    "display(HTML(u'<font color=\"green\">Зеленый!</font>'))\n",
    "display(HTML(u'<a href=\"http://yandex.ru\">Еще один вариант вывода ссылки</a>'))\n",
    "for i, theme in enumerate(topic_labels):\n",
    "    display(HTML(\"<h3>%s</h3>\" % theme))\n",
    "    for j in range(10):\n",
    "        print(tokens[model_artm.topic_names[i]][j]),\n",
    "    print('')\n",
    "    for k in range(10):\n",
    "        print(theta.columns[prob_doc_theme_sorted_indices[i,k]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
