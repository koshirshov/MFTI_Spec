{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример использования библиотеки gensim для тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/maxis42/ML-DA-Coursera-Yandex-MIPT/blob/master/3%20Unsupervised%20learning/Homework/4%20text%20themes/edit_CookingLDA_PA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая полезная теорема Байеса! :)\n",
    "\n",
    "![comic1](http://imgs.xkcd.com/comics/seashell.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'artm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-689dcb277cfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0martm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'artm'"
     ]
    }
   ],
   "source": [
    "import artm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Импортируем данные в формте UCI Bag of Words\n",
    "data = corpora.UciCorpus(\"C:/users/Kostya/python scripts/CSV/docword.xkcd.txt\"\n",
    "                         , \"C:/users/Kostya/python scripts/CSV/vocab.xkcd.txt\")\n",
    "dictionary = data.create_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'sits'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#удалили из текста стоп слова, знаки, лемматизация\n",
    "#матрица частот слов, которая представлена вот так:\n",
    "#1я строка - число документов. 2я - число уник слов. 3я - всего слов\n",
    "#дальше - строки из 3х чисел : номер документа, номер слова, сколько раз встретилось в документе\n",
    "#нумерация с 1 \n",
    "#тексты во втором файле - файл словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "# обучение модель\n",
    "%time ldamodel = models.ldamodel.LdaModel(data, id2word=dictionary, num_topics=5, passes=20, alpha=1.25, eta=1.25)#, distributed=True)\n",
    "#data - corpus, id2word - отображение индексов слов в сами слова;passes - сколько раз проходить по коллекции, если она не большая\n",
    "#если большая коллекция - 1/2 прохода, но тчательно подобрать другие параметры\n",
    "#aapha i eta - априорные параметры распределения Дирихле. Если все числа одинаковы - то симметричное распределение. (числа в векторе)\n",
    "#можно число, можно вектор, можно строку symmetric / assymetric, auto - подберет ассиметричное оптимальное\n",
    "#часто сгодится просто числа от 0 до 2, чтобы получилось ок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сохранение модели\n",
    "ldamodel.save(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "ldamodel = models.ldamodel.LdaModel.load(\"ldamodel_xkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.023*\"b'man'\" + 0.012*\"b'text'\" + 0.011*\"b'person'\" + 0.011*\"b'title'\" + 0.009*\"b'woman'\" + 0.008*\"b'guy'\" + 0.006*\"b'one'\" + 0.006*\"b'girl'\" + 0.005*\"b'just'\" + 0.005*\"b'two'\"\n",
      "Topic 1 : 0.003*\"b'day'\" + 0.002*\"b'scientist'\" + 0.002*\"b'map'\" + 0.002*\"b'text'\" + 0.002*\"b'title'\" + 0.001*\"b'island'\" + 0.001*\"b'number'\" + 0.001*\"b'dot'\" + 0.001*\"b'one'\" + 0.001*\"b'google'\"\n",
      "Topic 2 : 0.001*\"b'wave'\" + 0.001*\"b'human'\" + 0.001*\"b'beef'\" + 0.001*\"b'hit'\" + 0.001*\"b'peak'\" + 0.001*\"b'cat'\" + 0.001*\"b'ray'\" + 0.001*\"b'entropy'\" + 0.001*\"b'bit'\" + 0.001*\"b'date'\"\n",
      "Topic 3 : 0.002*\"b'link'\" + 0.001*\"b'person'\" + 0.001*\"b'goggles'\" + 0.001*\"b'jelly'\" + 0.001*\"b'bean'\" + 0.001*\"b'error'\" + 0.001*\"b'nathan'\" + 0.001*\"b'found'\" + 0.001*\"b'acne'\" + 0.001*\"b'005'\"\n",
      "Topic 4 : 0.003*\"b'line'\" + 0.002*\"b'wait'\" + 0.002*\"b'labeled'\" + 0.002*\"b'paul'\" + 0.001*\"b'one'\" + 0.001*\"b'within'\" + 0.001*\"b'peter'\" + 0.001*\"b'sagal'\" + 0.001*\"b'ron'\" + 0.001*\"b'point'\"\n"
     ]
    }
   ],
   "source": [
    "# выводим топы слов\n",
    "for t, top_words in ldamodel.print_topics(num_topics=10, num_words=10):\n",
    "    print (\"Topic\", t, \":\", top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350.504663321\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем логарифм перплексии и немного преобразуем, чтобы привести к общепринятому виду\n",
    "perplexity = ldamodel.log_perplexity(list(data))\n",
    "print (2**(-perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350.50466267682589"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp = ldamodel.bound(data)\n",
    "2**(-perp/float(87409))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-f09218b8da97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Добавление в модель новых документов, содержащихся в новом корупсе data2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data2' is not defined"
     ]
    }
   ],
   "source": [
    "# Добавление в модель новых документов, содержащихся в новом корупсе data2\n",
    "ldamodel.update(data2, passes=10)\n",
    "#дообучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.75333375),\n",
       " (1, 0.06842801),\n",
       " (2, 0.055349473),\n",
       " (3, 0.056624401),\n",
       " (4, 0.066264361)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Получение распределения тем для конкретного документа\n",
    "doc = list(data)[0]\n",
    "ldamodel.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти люди не знают про тематические модели:\n",
    "\n",
    "![comic2](http://imgs.xkcd.com/comics/the_problem_with_wikipedia.png) | ![comic3](http://imgs.xkcd.com/comics/mystery_news.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
